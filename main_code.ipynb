{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6fb62588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "600b4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('C:/Users/HP/Desktop/flower.jpg')\n",
    "image = cv2.resize(image, (720, 640))\n",
    "\n",
    "face1 = \"C:/Users/HP/Downloads/opencv_face_detector.pbtxt\"\n",
    "face2 = \"C:/Users/HP/Downloads/opencv_face_detector_uint8.pb\"\n",
    "\n",
    "gen1 = \"C:/Users/HP/Downloads/gender_deploy.prototxt\"\n",
    "gen2 = \"C:/Users/HP/Downloads/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "face = cv2.dnn.readNet(face2, face1)\n",
    "\n",
    "gen = cv2.dnn.readNet(gen2, gen1)\n",
    "\n",
    "la = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
    "'(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "lg = ['Male', 'Female']\n",
    "\n",
    "\n",
    "fr_cv = image.copy()\n",
    "fr_h = fr_cv.shape[0]\n",
    "fr_w = fr_cv.shape[1]\n",
    "blob = cv2.dnn.blobFromImage(fr_cv, 1.0, (300, 300),[104, 117, 123], True, False)\n",
    "\n",
    "face.setInput(blob)\n",
    "detections = face.forward()\n",
    "faceBoxes = []\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence > 0.7:\n",
    "\n",
    "        x1 = int(detections[0, 0, i, 3]*fr_w)\n",
    "        y1 = int(detections[0, 0, i, 4]*fr_h)\n",
    "        x2 = int(detections[0, 0, i, 5]*fr_w)\n",
    "        y2 = int(detections[0, 0, i, 6]*fr_h)\n",
    "\n",
    "        faceBoxes.append([x1, y1, x2, y2])\n",
    "\n",
    "        cv2.rectangle(fr_cv, (x1, y1), (x2, y2), (0, 255, 0), int(round(fr_h/150)), 8)\n",
    "\n",
    "\n",
    "\n",
    "if not faceBoxes:\n",
    "    print(\"No face detected\")\n",
    "\n",
    "for faceBox in faceBoxes:\n",
    "\n",
    "    face = fr_cv[max(0, faceBox[1]-15):\n",
    "    min(faceBox[3]+15, fr_cv.shape[0]-1),\n",
    "    max(0, faceBox[0]-15):min(faceBox[2]+15,\n",
    "    fr_cv.shape[1]-1)]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "    \n",
    "    gen.setInput(blob)\n",
    "    genderPreds = gen.forward()\n",
    "    gender = lg[genderPreds[0].argmax()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.putText(fr_cv,\n",
    "    f'{gender}',\n",
    "    (faceBox[0]-150, faceBox[1]+10),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    1.1,\n",
    "    (217, 0, 0),\n",
    "    4,\n",
    "    cv2.LINE_AA)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(fr_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
